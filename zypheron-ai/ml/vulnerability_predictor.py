"""
ML-Powered Vulnerability Prediction
Uses machine learning to predict vulnerabilities before exploitation
"""

from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
import re
import numpy as np
from loguru import logger

try:
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.feature_extraction.text import TfidfVectorizer
    import pickle
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logger.warning("scikit-learn not available - ML prediction disabled")

from providers.manager import ai_manager
from providers.base import AIMessage


@dataclass
class VulnerabilityPrediction:
    """ML Vulnerability Prediction Result"""
    vulnerability_type: str
    confidence: float
    severity: str
    reasoning: str
    affected_components: List[str]
    recommended_tests: List[str]


class MLVulnerabilityPredictor:
    """
    ML-based vulnerability predictor
    Predicts potential vulnerabilities based on service configurations,
    versions, and historical CVE data
    """
    
    def __init__(self):
        self.vectorizer = None
        self.classifier = None
        self.vulnerability_patterns = self._load_vulnerability_patterns()
        self.initialized = False
    
    def _load_vulnerability_patterns(self) -> Dict[str, List[str]]:
        """Load known vulnerability patterns"""
        return {
            'sql_injection': [
                r'mysql.*version\s+(\d+\.\d+)',
                r'postgresql.*version\s+(\d+\.\d+)',
                r'mssql',
                r'oracle',
            ],
            'xss': [
                r'php.*version\s+(\d+\.\d+)',
                r'apache.*version\s+(\d+\.\d+)',
                r'nginx',
                r'wordpress',
            ],
            'rce': [
                r'apache.*struts',
                r'log4j',
                r'spring.*framework',
                r'tomcat.*version\s+(\d+\.\d+)',
            ],
            'authentication_bypass': [
                r'admin',
                r'default.*password',
                r'anonymous.*access',
                r'weak.*credentials',
            ],
            'information_disclosure': [
                r'directory.*listing',
                r'phpinfo',
                r'\.git',
                r'\.env',
                r'backup',
            ],
            'deserialization': [
                r'java.*version',
                r'pickle',
                r'yaml.*load',
                r'serialization',
            ],
            'xxe': [
                r'xml.*parser',
                r'libxml',
                r'xerces',
            ],
            'ssrf': [
                r'curl',
                r'urllib',
                r'requests',
                r'httpclient',
            ],
        }
    
    async def predict_vulnerabilities(
        self,
        scan_data: Dict[str, Any],
        use_ai: bool = True
    ) -> List[VulnerabilityPrediction]:
        """
        Predict potential vulnerabilities based on scan data
        
        Args:
            scan_data: Dictionary containing scan results (services, versions, configs)
            use_ai: Whether to use AI for enhanced predictions
        
        Returns:
            List of vulnerability predictions
        """
        logger.info("Running ML vulnerability prediction...")
        
        predictions = []
        
        # Pattern-based prediction (fast, rule-based)
        pattern_predictions = self._pattern_based_prediction(scan_data)
        predictions.extend(pattern_predictions)
        
        # ML-based prediction (if model is trained)
        if SKLEARN_AVAILABLE and self.initialized:
            ml_predictions = self._ml_based_prediction(scan_data)
            predictions.extend(ml_predictions)
        
        # AI-enhanced prediction (most accurate)
        if use_ai:
            ai_predictions = await self._ai_enhanced_prediction(scan_data, predictions)
            predictions.extend(ai_predictions)
        
        # Remove duplicates and sort by confidence
        predictions = self._deduplicate_predictions(predictions)
        predictions.sort(key=lambda p: p.confidence, reverse=True)
        
        return predictions
    
    def _pattern_based_prediction(
        self,
        scan_data: Dict[str, Any]
    ) -> List[VulnerabilityPrediction]:
        """Use regex patterns to predict vulnerabilities"""
        predictions = []
        
        # Extract text data from scan results
        scan_text = str(scan_data).lower()
        
        for vuln_type, patterns in self.vulnerability_patterns.items():
            for pattern in patterns:
                if re.search(pattern, scan_text, re.IGNORECASE):
                    # Found a potential vulnerability indicator
                    confidence = 0.6  # Base confidence for pattern match
                    
                    # Extract version if present
                    version_match = re.search(r'version\s+(\d+\.\d+)', scan_text)
                    affected_component = version_match.group(0) if version_match else "unknown"
                    
                    # Determine severity
                    severity = self._estimate_severity(vuln_type)
                    
                    # Generate recommended tests
                    tests = self._generate_recommended_tests(vuln_type)
                    
                    predictions.append(VulnerabilityPrediction(
                        vulnerability_type=vuln_type,
                        confidence=confidence,
                        severity=severity,
                        reasoning=f"Pattern match: {pattern}",
                        affected_components=[affected_component],
                        recommended_tests=tests,
                    ))
        
        return predictions
    
    def _ml_based_prediction(
        self,
        scan_data: Dict[str, Any]
    ) -> List[VulnerabilityPrediction]:
        """Use trained ML model to predict vulnerabilities"""
        if not SKLEARN_AVAILABLE or not self.classifier:
            return []
        
        try:
            # Extract features from scan data
            features = self._extract_features(scan_data)
            
            # Predict with ML model
            probabilities = self.classifier.predict_proba([features])[0]
            predictions = []
            
            for idx, prob in enumerate(probabilities):
                if prob > 0.4:  # Confidence threshold
                    vuln_type = self.classifier.classes_[idx]
                    predictions.append(VulnerabilityPrediction(
                        vulnerability_type=vuln_type,
                        confidence=float(prob),
                        severity=self._estimate_severity(vuln_type),
                        reasoning="ML model prediction",
                        affected_components=["detected by ML"],
                        recommended_tests=self._generate_recommended_tests(vuln_type),
                    ))
            
            return predictions
        
        except Exception as e:
            logger.error(f"ML prediction failed: {e}")
            return []
    
    async def _ai_enhanced_prediction(
        self,
        scan_data: Dict[str, Any],
        existing_predictions: List[VulnerabilityPrediction]
    ) -> List[VulnerabilityPrediction]:
        """Use AI to enhance and validate predictions"""
        
        try:
            # Prepare context for AI
            scan_summary = str(scan_data)[:2000]  # Limit size
            
            existing_summary = "\n".join([
                f"- {p.vulnerability_type} (confidence: {p.confidence:.2f})"
                for p in existing_predictions[:5]
            ])
            
            messages = [
                AIMessage(
                    role="system",
                    content="""You are an expert penetration tester with deep knowledge of 
vulnerability research. Analyze the scan data and predict potential vulnerabilities 
that may not be immediately obvious."""
                ),
                AIMessage(
                    role="user",
                    content=f"""Based on this scan data:

{scan_summary}

Existing predictions:
{existing_summary}

Predict additional vulnerabilities that:
1. May not be directly visible in the scan
2. Could arise from service interactions
3. Are related to configuration weaknesses
4. Represent emerging attack vectors

For each prediction, provide:
- Vulnerability type
- Confidence (0-1)
- Severity (critical/high/medium/low)
- Reasoning
- Components likely affected
- Recommended security tests

Format as structured list."""
                )
            ]
            
            response = await ai_manager.chat(messages=messages, temperature=0.4)
            
            # Parse AI response (in production, use structured output)
            ai_predictions = self._parse_ai_predictions(response.content)
            
            return ai_predictions
        
        except Exception as e:
            logger.error(f"AI-enhanced prediction failed: {e}")
            return []
    
    def _parse_ai_predictions(self, ai_response: str) -> List[VulnerabilityPrediction]:
        """Parse AI response into structured predictions"""
        predictions = []
        
        # Simple parsing logic (in production, use structured JSON output)
        lines = ai_response.split('\n')
        current_pred = {}
        
        for line in lines:
            line = line.strip()
            
            if 'vulnerability type:' in line.lower():
                if current_pred:
                    predictions.append(self._dict_to_prediction(current_pred))
                current_pred = {'type': line.split(':', 1)[1].strip()}
            elif 'confidence:' in line.lower():
                try:
                    conf_str = line.split(':', 1)[1].strip().rstrip('%')
                    current_pred['confidence'] = float(conf_str) / 100 if '%' in line else float(conf_str)
                except:
                    current_pred['confidence'] = 0.5
            elif 'severity:' in line.lower():
                current_pred['severity'] = line.split(':', 1)[1].strip().lower()
            elif 'reasoning:' in line.lower():
                current_pred['reasoning'] = line.split(':', 1)[1].strip()
        
        if current_pred:
            predictions.append(self._dict_to_prediction(current_pred))
        
        return predictions
    
    def _dict_to_prediction(self, data: Dict) -> VulnerabilityPrediction:
        """Convert dictionary to VulnerabilityPrediction"""
        return VulnerabilityPrediction(
            vulnerability_type=data.get('type', 'unknown'),
            confidence=data.get('confidence', 0.5),
            severity=data.get('severity', 'medium'),
            reasoning=data.get('reasoning', 'AI analysis'),
            affected_components=[],
            recommended_tests=[],
        )
    
    def _extract_features(self, scan_data: Dict[str, Any]) -> List[float]:
        """Extract numerical features from scan data for ML"""
        features = []
        
        scan_text = str(scan_data).lower()
        
        # Feature: Number of open ports
        features.append(scan_text.count('open'))
        
        # Feature: Presence of common services
        features.append(1 if 'http' in scan_text else 0)
        features.append(1 if 'ssh' in scan_text else 0)
        features.append(1 if 'ftp' in scan_text else 0)
        features.append(1 if 'sql' in scan_text else 0)
        
        # Feature: Presence of version information
        features.append(1 if re.search(r'version\s+\d+', scan_text) else 0)
        
        # Feature: Presence of default credentials
        features.append(1 if 'default' in scan_text or 'admin' in scan_text else 0)
        
        return features
    
    def _estimate_severity(self, vuln_type: str) -> str:
        """Estimate severity based on vulnerability type"""
        critical_types = ['rce', 'authentication_bypass', 'deserialization']
        high_types = ['sql_injection', 'xss', 'xxe', 'ssrf']
        
        if vuln_type in critical_types:
            return 'critical'
        elif vuln_type in high_types:
            return 'high'
        else:
            return 'medium'
    
    def _generate_recommended_tests(self, vuln_type: str) -> List[str]:
        """Generate recommended security tests for a vulnerability type"""
        tests = {
            'sql_injection': [
                'sqlmap --url <target> --batch',
                'Manual: Test with \' OR \'1\'=\'1',
                'Test error-based injection',
            ],
            'xss': [
                'Test with <script>alert(1)</script>',
                'Test reflected XSS in parameters',
                'Check for DOM-based XSS',
            ],
            'rce': [
                'Test command injection: ; ls -la',
                'Check for unrestricted file upload',
                'Test deserialization exploits',
            ],
            'authentication_bypass': [
                'Test default credentials',
                'Check for JWT vulnerabilities',
                'Test session fixation',
            ],
        }
        
        return tests.get(vuln_type, ['Manual security review recommended'])
    
    def _deduplicate_predictions(
        self,
        predictions: List[VulnerabilityPrediction]
    ) -> List[VulnerabilityPrediction]:
        """Remove duplicate predictions"""
        seen = set()
        unique = []
        
        for pred in predictions:
            key = (pred.vulnerability_type, pred.severity)
            if key not in seen:
                seen.add(key)
                unique.append(pred)
        
        return unique
    
    def train_model(self, training_data: List[Tuple[Dict, List[str]]]):
        """
        Train the ML model with historical scan data
        
        Args:
            training_data: List of (scan_data, vulnerability_labels) tuples
        """
        if not SKLEARN_AVAILABLE:
            logger.error("scikit-learn not available for training")
            return
        
        logger.info(f"Training ML model with {len(training_data)} samples...")
        
        # Extract features and labels
        X = [self._extract_features(scan) for scan, _ in training_data]
        y = [labels for _, labels in training_data]
        
        # Train classifier
        self.classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        # Note: This is simplified - in production, use MultiLabelBinarizer for multi-label classification
        # For now, just using the first label
        y_simplified = [labels[0] if labels else 'unknown' for labels in y]
        self.classifier.fit(X, y_simplified)
        
        self.initialized = True
        logger.info("ML model training complete")
    
    def save_model(self, path: str):
        """Save trained model to disk"""
        if not self.classifier:
            raise ValueError("No model to save")
        
        import pickle
        with open(path, 'wb') as f:
            pickle.dump({
                'classifier': self.classifier,
                'vectorizer': self.vectorizer,
            }, f)
        
        logger.info(f"Model saved to {path}")
    
    def load_model(self, path: str):
        """Load trained model from disk"""
        import pickle
        with open(path, 'rb') as f:
            data = pickle.load(f)
            self.classifier = data['classifier']
            self.vectorizer = data['vectorizer']
        
        self.initialized = True
        logger.info(f"Model loaded from {path}")

